Could not find platform independent libraries <prefix>
Could not find platform dependent libraries <exec_prefix>
Consider setting $PYTHONHOME to <prefix>[:<exec_prefix>]
ImportError: No module named site
Job start at Tue Jun  8 10:14:37 CEST 2021
Running job on machine Linux b7s12n1006.cern.ch 3.10.0-1160.21.1.el7.x86_64 #1 SMP Tue Mar 16 18:28:22 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux, host b7s12n1006.cern.ch
============================================================
$PWD=/pool/condor/dir_9703
$JOBID=2368945
$TASKID=17
$HOSTNAME=b7s12n1006.cern.ch
$TASKCMD=/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/python/processors/picojob.py -y UL2017 -d 'mc' -c etau -M ETauFakeRate.ModuleETau --copydir /eos/home-l/lvigilan/output_ETauFR_UL17_RUN1/UL2017/etau/W3JetsToLNu -t _etau_EES1p01_17 --opt 'ees=1.01' 'useT1=True' -i /eos/cms/store/group/phys_tau/TauFW/nano/UL2017/W3JetsToLNu_TuneCP5_13TeV-madgraphMLM-pythia8/RunIISummer19UL17NanoAODv2-106X_mc2017_realistic_v8-v1/NANOAODSIM/EB6B09FF-62D2-1842-8B4F-A9CAF91ECC8E_skimjec_4.root
$WORKDIR=/pool/condor/dir_9703
>>> cd /afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src
>>> eval `scramv1 runtime -sh`
>>> cd /pool/condor/dir_9703
$PWD=/pool/condor/dir_9703
>>> /afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/python/processors/picojob.py -y UL2017 -d 'mc' -c etau -M ETauFakeRate.ModuleETau --copydir /eos/home-l/lvigilan/output_ETauFR_UL17_RUN1/UL2017/etau/W3JetsToLNu -t _etau_EES1p01_17 --opt 'ees=1.01' 'useT1=True' -i /eos/cms/store/group/phys_tau/TauFW/nano/UL2017/W3JetsToLNu_TuneCP5_13TeV-madgraphMLM-pythia8/RunIISummer19UL17NanoAODv2-106X_mc2017_realistic_v8-v1/NANOAODSIM/EB6B09FF-62D2-1842-8B4F-A9CAF91ECC8E_skimjec_4.root
Error in <TGClient::TGClient>: can't open display "localhost:21.0", switching to batch mode...
 In case you run from a remote ssh session, reconnect with ssh -Y
--------------------------------------------------------------------------------
>>> era          = 'UL2017'
>>> year         = 2017
>>> channel      = 'etau'
>>> modname      = 'ETauFakeRate.ModuleETau'
>>> dtype        = 'mc'
>>> kwargs       = {'dtype': 'mc', 'ees': 1.01, 'useT1': True, 'verb': 0, 'era': 'UL2017', 'year': 2017}
>>> firstevt     = 0
>>> maxevts      = None
>>> outdir       = '.'
>>> copydir      = '/eos/home-l/lvigilan/output_ETauFR_UL17_RUN1/UL2017/etau/W3JetsToLNu'
>>> infiles      = ['/eos/cms/store/group/phys_tau/TauFW/nano/UL2017/W3JetsToLNu_TuneCP5_13TeV-madgraphMLM-pythia8/RunIISummer19UL17NanoAODv2-106X_mc2017_realistic_v8-v1/NANOAODSIM/EB6B09FF-62D2-1842-8B4F-A9CAF91ECC8E_skimjec_4.root']
>>> outfname     = './pico_etau_EES1p01_17.root'
>>> branchsel    = '/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/python/TauFW/PicoProducer/processors/keep_and_drop_skim.txt'
>>> json         = None
>>> prefetch     = False
>>> cwd          = /pool/condor/dir_9703
--------------------------------------------------------------------------------

   ################
   #  ModuleETau  #
   ################

Loading PileupWeightTool for '/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/data/pileup/Data_PileUp_UL2017_69p2.root' and '/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/data/pileup/MC_PileUp_UL2017_Summer19.root'
Loading BTagWeightTool for DeepCSV (medium WP)...
>>> BTagTool: [1m[33mWarning! [0m[33mHistogram 'etau/eff_DeepCSV_udsg_medium' does not exist in /afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/data/btag/DeepCSV_2017_12Apr2017_eff.root! Reverting to default efficiency histogram...[0m
>>> BTagTool: [1m[33mWarning! [0m[33mHistogram 'etau/eff_DeepCSV_c_medium' does not exist in /afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/data/btag/DeepCSV_2017_12Apr2017_eff.root! Reverting to default efficiency histogram...[0m
>>> BTagTool: [1m[33mWarning! [0m[33mHistogram 'etau/eff_DeepCSV_b_medium' does not exist in /afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/data/btag/DeepCSV_2017_12Apr2017_eff.root! Reverting to default efficiency histogram...[0m
>>> BTagTool: [1m[33mWarning! [0m[33mMade use of default efficiency histograms! The b tag weights from this module should be regarded as placeholders only,
and should NOT be used for analyses. B (mis)tag efficiencies in MC are analysis dependent. Please create your own
efficiency histogram with data/btag/getBTagEfficiencies.py after running all MC samples with BTagWeightTool.[0m
Loading TreeProducerETau for './pico_etau_EES1p01_17.root'
--------------------------------------------------------------------------------
>>> filename     = './pico_etau_EES1p01_17.root'
>>> year         = 2017
>>> dtype        = 'mc'
>>> channel      = 'etau'
>>> ismc         = True
>>> isdata       = False
>>> isembed      = False
>>> tes          = 1.0
>>> tessys       = None
>>> fes          = None
>>> ltf          = None
>>> jtf          = 1.0
>>> dotoppt      = False
>>> dozpt        = False
>>> dojec        = True
>>> dojecsys     = True
>>> dotight      = False
>>> useT1        = True
>>> jetCutPt     = 30
>>> bjetCutEta   = 2.7
>>> tauwp        = 0
>>> eleCutPt     = 36
>>> eleCutEta    = 2.1
>>> tauCutPt     = 20
>>> tauCutEta    = 2.3
>>> ZpeekReso    = 0.1
Pre-select 223858 entries out of 223858 (100.00%)
Processed    10000/  223858 entries,  4.47% (elapsed time     5.6s, curr speed    1.788 kHz, avg speed    1.788 kHz), accepted       96/   10001 events ( 0.96%)
Processed    20000/  223858 entries,  8.93% (elapsed time     7.1s, curr speed    6.448 kHz, avg speed    2.800 kHz), accepted      197/   20001 events ( 0.98%)
Processed    30000/  223858 entries, 13.40% (elapsed time     8.6s, curr speed    6.682 kHz, avg speed    3.472 kHz), accepted      323/   30001 events ( 1.08%)
Processed    40000/  223858 entries, 17.87% (elapsed time    11.8s, curr speed    3.181 kHz, avg speed    3.395 kHz), accepted      443/   40001 events ( 1.11%)
Processed    50000/  223858 entries, 22.34% (elapsed time    13.0s, curr speed    8.337 kHz, avg speed    3.851 kHz), accepted      573/   50001 events ( 1.15%)
Processed    60000/  223858 entries, 26.80% (elapsed time    14.1s, curr speed    9.116 kHz, avg speed    4.261 kHz), accepted      708/   60001 events ( 1.18%)
Processed    70000/  223858 entries, 31.27% (elapsed time    15.1s, curr speed    9.975 kHz, avg speed    4.641 kHz), accepted      825/   70001 events ( 1.18%)
Processed    80000/  223858 entries, 35.74% (elapsed time    16.1s, curr speed    9.580 kHz, avg speed    4.961 kHz), accepted      932/   80001 events ( 1.16%)
Processed    90000/  223858 entries, 40.20% (elapsed time    17.2s, curr speed    9.153 kHz, avg speed    5.227 kHz), accepted     1028/   90001 events ( 1.14%)
Processed   100000/  223858 entries, 44.67% (elapsed time    18.3s, curr speed    9.396 kHz, avg speed    5.470 kHz), accepted     1144/  100001 events ( 1.14%)
Processed   110000/  223858 entries, 49.14% (elapsed time    19.3s, curr speed   10.108 kHz, avg speed    5.708 kHz), accepted     1247/  110001 events ( 1.13%)
Processed   120000/  223858 entries, 53.61% (elapsed time    20.7s, curr speed    7.003 kHz, avg speed    5.797 kHz), accepted     1336/  120001 events ( 1.11%)
Processed   130000/  223858 entries, 58.07% (elapsed time    24.9s, curr speed    2.364 kHz, avg speed    5.214 kHz), accepted     1434/  130001 events ( 1.10%)
Processed   140000/  223858 entries, 62.54% (elapsed time    27.2s, curr speed    4.448 kHz, avg speed    5.151 kHz), accepted     1554/  140001 events ( 1.11%)
Processed   150000/  223858 entries, 67.01% (elapsed time    28.3s, curr speed    9.242 kHz, avg speed    5.308 kHz), accepted     1664/  150001 events ( 1.11%)
Processed   160000/  223858 entries, 71.47% (elapsed time    29.4s, curr speed    9.118 kHz, avg speed    5.450 kHz), accepted     1766/  160001 events ( 1.10%)
Processed   170000/  223858 entries, 75.94% (elapsed time    30.6s, curr speed    8.255 kHz, avg speed    5.561 kHz), accepted     1870/  170001 events ( 1.10%)
Processed   180000/  223858 entries, 80.41% (elapsed time    31.7s, curr speed    8.789 kHz, avg speed    5.677 kHz), accepted     1973/  180001 events ( 1.10%)
Processed   190000/  223858 entries, 84.88% (elapsed time    32.8s, curr speed    9.126 kHz, avg speed    5.792 kHz), accepted     2088/  190001 events ( 1.10%)
Processed   200000/  223858 entries, 89.34% (elapsed time    33.9s, curr speed    8.994 kHz, avg speed    5.897 kHz), accepted     2209/  200001 events ( 1.10%)
Processed   210000/  223858 entries, 93.81% (elapsed time    35.0s, curr speed    8.874 kHz, avg speed    5.993 kHz), accepted     2324/  210001 events ( 1.11%)
Processed   220000/  223858 entries, 98.28% (elapsed time    36.2s, curr speed    8.976 kHz, avg speed    6.085 kHz), accepted     2434/  220001 events ( 1.11%)
Processed 223858 preselected entries from /eos/cms/store/group/phys_tau/TauFW/nano/UL2017/W3JetsToLNu_TuneCP5_13TeV-madgraphMLM-pythia8/RunIISummer19UL17NanoAODv2-106X_mc2017_realistic_v8-v1/NANOAODSIM/EB6B09FF-62D2-1842-8B4F-A9CAF91ECC8E_skimjec_4.root (223858 entries). Finally selected 2472 entries
Total time 37.0 sec. to process 223858 events. Rate = 6057.4 Hz.
>>> cwd          = /pool/condor/dir_9703
>>> ls           = ['lvigilan.cc', '_condor_stdout', 'condor_exec.exe', 'var', 'x509_voms', '.chirp.config', '.job.ad', 'pico_etau_EES1p01_17.root', '.machine.ad', 'tmp']
>>> getstorage('/eos/home-l/lvigilan/output_ETauFR_UL17_RUN1/UL2017/etau/W3JetsToLNu'), <EOS("/eos/home-l/lvigilan/output_ETauFR_UL17_RUN1/UL2017/etau/W3JetsToLNu") at 0x2b444f350d50>
>>> Executing: 'cp ./pico_etau_EES1p01_17.root /eos/home-l/lvigilan/output_ETauFR_UL17_RUN1/UL2017/etau/W3JetsToLNu'
>>> Removing './pico_etau_EES1p01_17.root'...
>>> picojob.py done after 47.9 seconds

Job complete at Tue Jun  8 10:15:26 CEST 2021
Took 0 minutes 49 seconds040 (2368945.017.000) 06/08 10:15:26 Finished transferring output files
...
005 (2368945.017.000) 06/08 10:15:26 Job terminated.
	(1) Normal termination (return value 0)
		Usr 0 00:00:30, Sys 0 00:00:01  -  Run Remote Usage
		Usr 0 00:00:00, Sys 0 00:00:00  -  Run Local Usage
		Usr 0 00:00:30, Sys 0 00:00:01  -  Total Remote Usage
		Usr 0 00:00:00, Sys 0 00:00:00  -  Total Local Usage
	17261  -  Run Bytes Sent By Job
	9926  -  Run Bytes Received By Job
	17261  -  Total Bytes Sent By Job
	9926  -  Total Bytes Received By Job
	Partitionable Resources :    Usage  Request Allocated 
	   Cpus                 :                 1         1 
	   Disk (KB)            :       77        1    282933 
	   Memory (MB)          :      200     2000      2000 

	Job terminated of its own accord at 2021-06-08T08:15:26Z.
...
