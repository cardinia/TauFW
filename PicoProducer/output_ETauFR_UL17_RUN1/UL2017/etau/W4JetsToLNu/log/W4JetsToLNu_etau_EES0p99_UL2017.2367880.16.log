Could not find platform independent libraries <prefix>
Could not find platform dependent libraries <exec_prefix>
Consider setting $PYTHONHOME to <prefix>[:<exec_prefix>]
ImportError: No module named site
Job start at Mon Jun  7 23:03:46 CEST 2021
Running job on machine Linux b7s11n0224.cern.ch 3.10.0-1160.21.1.el7.x86_64 #1 SMP Tue Mar 16 18:28:22 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux, host b7s11n0224.cern.ch
============================================================
$PWD=/pool/condor/dir_30739
$JOBID=2367880
$TASKID=16
$HOSTNAME=b7s11n0224.cern.ch
$TASKCMD=/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/python/processors/picojob.py -y UL2017 -d 'mc' -c etau -M ETauFakeRate.ModuleETau --copydir /eos/home-l/lvigilan/output_ETauFR_UL17_RUN1/UL2017/etau/W4JetsToLNu -t _etau_EES0p99_16 --opt 'ees=0.99' 'useT1=True' -i /eos/cms/store/group/phys_tau/TauFW/nano/UL2017/W4JetsToLNu_TuneCP5_13TeV-madgraphMLM-pythia8/RunIISummer19UL17NanoAODv2-106X_mc2017_realistic_v8-v1/NANOAODSIM/F579CE3B-EF28-5B4A-AF74-7D9202D55CAD_skimjec_1.root
$WORKDIR=/pool/condor/dir_30739
>>> cd /afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src
>>> eval `scramv1 runtime -sh`
>>> cd /pool/condor/dir_30739
$PWD=/pool/condor/dir_30739
>>> /afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/python/processors/picojob.py -y UL2017 -d 'mc' -c etau -M ETauFakeRate.ModuleETau --copydir /eos/home-l/lvigilan/output_ETauFR_UL17_RUN1/UL2017/etau/W4JetsToLNu -t _etau_EES0p99_16 --opt 'ees=0.99' 'useT1=True' -i /eos/cms/store/group/phys_tau/TauFW/nano/UL2017/W4JetsToLNu_TuneCP5_13TeV-madgraphMLM-pythia8/RunIISummer19UL17NanoAODv2-106X_mc2017_realistic_v8-v1/NANOAODSIM/F579CE3B-EF28-5B4A-AF74-7D9202D55CAD_skimjec_1.root
Error in <TGClient::TGClient>: can't open display "localhost:13.0", switching to batch mode...
 In case you run from a remote ssh session, reconnect with ssh -Y
--------------------------------------------------------------------------------
>>> era          = 'UL2017'
>>> year         = 2017
>>> channel      = 'etau'
>>> modname      = 'ETauFakeRate.ModuleETau'
>>> dtype        = 'mc'
>>> kwargs       = {'dtype': 'mc', 'ees': 0.99, 'useT1': True, 'verb': 0, 'era': 'UL2017', 'year': 2017}
>>> firstevt     = 0
>>> maxevts      = None
>>> outdir       = '.'
>>> copydir      = '/eos/home-l/lvigilan/output_ETauFR_UL17_RUN1/UL2017/etau/W4JetsToLNu'
>>> infiles      = ['/eos/cms/store/group/phys_tau/TauFW/nano/UL2017/W4JetsToLNu_TuneCP5_13TeV-madgraphMLM-pythia8/RunIISummer19UL17NanoAODv2-106X_mc2017_realistic_v8-v1/NANOAODSIM/F579CE3B-EF28-5B4A-AF74-7D9202D55CAD_skimjec_1.root']
>>> outfname     = './pico_etau_EES0p99_16.root'
>>> branchsel    = '/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/python/TauFW/PicoProducer/processors/keep_and_drop_skim.txt'
>>> json         = None
>>> prefetch     = False
>>> cwd          = /pool/condor/dir_30739
--------------------------------------------------------------------------------

   ################
   #  ModuleETau  #
   ################

Loading PileupWeightTool for '/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/data/pileup/Data_PileUp_UL2017_69p2.root' and '/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/data/pileup/MC_PileUp_UL2017_Summer19.root'
Loading BTagWeightTool for DeepCSV (medium WP)...
>>> BTagTool: [1m[33mWarning! [0m[33mHistogram 'etau/eff_DeepCSV_udsg_medium' does not exist in /afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/data/btag/DeepCSV_2017_12Apr2017_eff.root! Reverting to default efficiency histogram...[0m
>>> BTagTool: [1m[33mWarning! [0m[33mHistogram 'etau/eff_DeepCSV_c_medium' does not exist in /afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/data/btag/DeepCSV_2017_12Apr2017_eff.root! Reverting to default efficiency histogram...[0m
>>> BTagTool: [1m[33mWarning! [0m[33mHistogram 'etau/eff_DeepCSV_b_medium' does not exist in /afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/data/btag/DeepCSV_2017_12Apr2017_eff.root! Reverting to default efficiency histogram...[0m
>>> BTagTool: [1m[33mWarning! [0m[33mMade use of default efficiency histograms! The b tag weights from this module should be regarded as placeholders only,
and should NOT be used for analyses. B (mis)tag efficiencies in MC are analysis dependent. Please create your own
efficiency histogram with data/btag/getBTagEfficiencies.py after running all MC samples with BTagWeightTool.[0m
Loading TreeProducerETau for './pico_etau_EES0p99_16.root'
--------------------------------------------------------------------------------
>>> filename     = './pico_etau_EES0p99_16.root'
>>> year         = 2017
>>> dtype        = 'mc'
>>> channel      = 'etau'
>>> ismc         = True
>>> isdata       = False
>>> isembed      = False
>>> tes          = 1.0
>>> tessys       = None
>>> fes          = None
>>> ltf          = None
>>> jtf          = 1.0
>>> dotoppt      = False
>>> dozpt        = False
>>> dojec        = True
>>> dojecsys     = True
>>> dotight      = False
>>> useT1        = True
>>> jetCutPt     = 30
>>> bjetCutEta   = 2.7
>>> tauwp        = 0
>>> eleCutPt     = 36
>>> eleCutEta    = 2.1
>>> tauCutPt     = 20
>>> tauCutEta    = 2.3
>>> ZpeekReso    = 0.1
Pre-select 228296 entries out of 228296 (100.00%)
Processed    10000/  228296 entries,  4.38% (elapsed time     6.0s, curr speed    1.664 kHz, avg speed    1.664 kHz), accepted      167/   10001 events ( 1.67%)
Processed    20000/  228296 entries,  8.76% (elapsed time     7.9s, curr speed    5.309 kHz, avg speed    2.534 kHz), accepted      325/   20001 events ( 1.62%)
Processed    30000/  228296 entries, 13.14% (elapsed time     9.8s, curr speed    5.262 kHz, avg speed    3.063 kHz), accepted      498/   30001 events ( 1.66%)
Processed    40000/  228296 entries, 17.52% (elapsed time    11.5s, curr speed    6.010 kHz, avg speed    3.491 kHz), accepted      645/   40001 events ( 1.61%)
Processed    50000/  228296 entries, 21.90% (elapsed time    13.1s, curr speed    6.129 kHz, avg speed    3.820 kHz), accepted      798/   50001 events ( 1.60%)
Processed    60000/  228296 entries, 26.28% (elapsed time    14.7s, curr speed    6.367 kHz, avg speed    4.093 kHz), accepted      940/   60001 events ( 1.57%)
Processed    70000/  228296 entries, 30.66% (elapsed time    16.4s, curr speed    5.724 kHz, avg speed    4.267 kHz), accepted     1081/   70001 events ( 1.54%)
Processed    80000/  228296 entries, 35.04% (elapsed time    19.4s, curr speed    3.295 kHz, avg speed    4.115 kHz), accepted     1214/   80001 events ( 1.52%)
Processed    90000/  228296 entries, 39.42% (elapsed time    21.2s, curr speed    5.786 kHz, avg speed    4.251 kHz), accepted     1356/   90001 events ( 1.51%)
Processed   100000/  228296 entries, 43.80% (elapsed time    23.3s, curr speed    4.756 kHz, avg speed    4.297 kHz), accepted     1511/  100001 events ( 1.51%)
Processed   110000/  228296 entries, 48.18% (elapsed time    25.2s, curr speed    5.262 kHz, avg speed    4.370 kHz), accepted     1650/  110001 events ( 1.50%)
Processed   120000/  228296 entries, 52.56% (elapsed time    26.5s, curr speed    7.677 kHz, avg speed    4.532 kHz), accepted     1776/  120001 events ( 1.48%)
Processed   130000/  228296 entries, 56.94% (elapsed time    29.1s, curr speed    3.815 kHz, avg speed    4.468 kHz), accepted     1938/  130001 events ( 1.49%)
Processed   140000/  228296 entries, 61.32% (elapsed time    30.8s, curr speed    5.772 kHz, avg speed    4.541 kHz), accepted     2093/  140001 events ( 1.49%)
Processed   150000/  228296 entries, 65.70% (elapsed time    33.1s, curr speed    4.389 kHz, avg speed    4.531 kHz), accepted     2227/  150001 events ( 1.48%)
Processed   160000/  228296 entries, 70.08% (elapsed time    34.9s, curr speed    5.567 kHz, avg speed    4.584 kHz), accepted     2406/  160001 events ( 1.50%)
Processed   170000/  228296 entries, 74.46% (elapsed time    36.7s, curr speed    5.615 kHz, avg speed    4.634 kHz), accepted     2532/  170001 events ( 1.49%)
Processed   180000/  228296 entries, 78.85% (elapsed time    38.7s, curr speed    5.001 kHz, avg speed    4.653 kHz), accepted     2672/  180001 events ( 1.48%)
Processed   190000/  228296 entries, 83.23% (elapsed time    40.4s, curr speed    5.828 kHz, avg speed    4.703 kHz), accepted     2826/  190001 events ( 1.49%)
Processed   200000/  228296 entries, 87.61% (elapsed time    42.6s, curr speed    4.618 kHz, avg speed    4.699 kHz), accepted     2969/  200001 events ( 1.48%)
Processed   210000/  228296 entries, 91.99% (elapsed time    44.5s, curr speed    5.148 kHz, avg speed    4.718 kHz), accepted     3122/  210001 events ( 1.49%)
Processed   220000/  228296 entries, 96.37% (elapsed time    46.5s, curr speed    4.937 kHz, avg speed    4.728 kHz), accepted     3291/  220001 events ( 1.50%)
Processed 228296 preselected entries from /eos/cms/store/group/phys_tau/TauFW/nano/UL2017/W4JetsToLNu_TuneCP5_13TeV-madgraphMLM-pythia8/RunIISummer19UL17NanoAODv2-106X_mc2017_realistic_v8-v1/NANOAODSIM/F579CE3B-EF28-5B4A-AF74-7D9202D55CAD_skimjec_1.root (228296 entries). Finally selected 3425 entries
Total time 48.6 sec. to process 228296 events. Rate = 4696.7 Hz.
>>> cwd          = /pool/condor/dir_30739
>>> ls           = ['_condor_stdout', 'tmp', '.chirp.config', 'pico_etau_EES0p99_16.root', 'condor_exec.exe', '.job.ad', 'x509_voms', '.machine.ad', 'lvigilan.cc', 'var']
>>> getstorage('/eos/home-l/lvigilan/output_ETauFR_UL17_RUN1/UL2017/etau/W4JetsToLNu'), <EOS("/eos/home-l/lvigilan/output_ETauFR_UL17_RUN1/UL2017/etau/W4JetsToLNu") at 0x2b0907a50d50>
>>> Executing: 'cp ./pico_etau_EES0p99_16.root /eos/home-l/lvigilan/output_ETauFR_UL17_RUN1/UL2017/etau/W4JetsToLNu'
>>> Removing './pico_etau_EES0p99_16.root'...
>>> picojob.py done after 80.0 seconds

Job complete at Mon Jun  7 23:05:09 CEST 2021
Took 1 minutes 23 seconds040 (2367880.016.000) 06/07 23:05:10 Started transferring output files
...
040 (2367880.016.000) 06/07 23:05:10 Finished transferring output files
...
005 (2367880.016.000) 06/07 23:05:11 Job terminated.
	(1) Normal termination (return value 0)
		Usr 0 00:00:51, Sys 0 00:00:02  -  Run Remote Usage
		Usr 0 00:00:00, Sys 0 00:00:00  -  Run Local Usage
		Usr 0 00:00:51, Sys 0 00:00:02  -  Total Remote Usage
		Usr 0 00:00:00, Sys 0 00:00:00  -  Total Local Usage
	17267  -  Run Bytes Sent By Job
	9898  -  Run Bytes Received By Job
	17267  -  Total Bytes Sent By Job
	9898  -  Total Bytes Received By Job
	Partitionable Resources :    Usage  Request Allocated 
	   Cpus                 :                 1         1 
	   Disk (KB)            :       77        1    165603 
	   Memory (MB)          :       29     2000      2000 

	Job terminated of its own accord at 2021-06-07T21:05:09Z.
...
