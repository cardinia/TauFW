Could not find platform independent libraries <prefix>
Could not find platform dependent libraries <exec_prefix>
Consider setting $PYTHONHOME to <prefix>[:<exec_prefix>]
ImportError: No module named site
Job start at Mon Jun  7 19:04:28 CEST 2021
Running job on machine Linux b7s11n9018.cern.ch 3.10.0-1160.24.1.el7.x86_64 #1 SMP Thu Apr 8 19:51:47 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux, host b7s11n9018.cern.ch
============================================================
$PWD=/pool/condor/dir_18951
$JOBID=2367592
$TASKID=105
$HOSTNAME=b7s11n9018.cern.ch
$TASKCMD=/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/python/processors/picojob.py -y UL2017 -d 'mc' -c etau -M ETauFakeRate.ModuleETau --copydir /eos/home-l/lvigilan/output_ETauFR_UL17_RUN1/UL2017/etau/TTToSemiLeptonic -t _etau_105 --opt 'useT1=True' 'toppt=True' -i /eos/cms/store/group/phys_tau/TauFW/nano/UL2017/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer19UL17NanoAODv2-106X_mc2017_realistic_v8-v1/NANOAODSIM/FFE9016D-DC64-4042-AA06-66288BF37B9B_skimjec_3.root
$WORKDIR=/pool/condor/dir_18951
>>> cd /afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src
>>> eval `scramv1 runtime -sh`
>>> cd /pool/condor/dir_18951
$PWD=/pool/condor/dir_18951
>>> /afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/python/processors/picojob.py -y UL2017 -d 'mc' -c etau -M ETauFakeRate.ModuleETau --copydir /eos/home-l/lvigilan/output_ETauFR_UL17_RUN1/UL2017/etau/TTToSemiLeptonic -t _etau_105 --opt 'useT1=True' 'toppt=True' -i /eos/cms/store/group/phys_tau/TauFW/nano/UL2017/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer19UL17NanoAODv2-106X_mc2017_realistic_v8-v1/NANOAODSIM/FFE9016D-DC64-4042-AA06-66288BF37B9B_skimjec_3.root
Error in <TGClient::TGClient>: can't open display "localhost:19.0", switching to batch mode...
 In case you run from a remote ssh session, reconnect with ssh -Y
--------------------------------------------------------------------------------
>>> era          = 'UL2017'
>>> year         = 2017
>>> channel      = 'etau'
>>> modname      = 'ETauFakeRate.ModuleETau'
>>> dtype        = 'mc'
>>> kwargs       = {'dtype': 'mc', 'toppt': True, 'useT1': True, 'verb': 0, 'era': 'UL2017', 'year': 2017}
>>> firstevt     = 0
>>> maxevts      = None
>>> outdir       = '.'
>>> copydir      = '/eos/home-l/lvigilan/output_ETauFR_UL17_RUN1/UL2017/etau/TTToSemiLeptonic'
>>> infiles      = ['/eos/cms/store/group/phys_tau/TauFW/nano/UL2017/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer19UL17NanoAODv2-106X_mc2017_realistic_v8-v1/NANOAODSIM/FFE9016D-DC64-4042-AA06-66288BF37B9B_skimjec_3.root']
>>> outfname     = './pico_etau_105.root'
>>> branchsel    = '/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/python/TauFW/PicoProducer/processors/keep_and_drop_skim.txt'
>>> json         = None
>>> prefetch     = False
>>> cwd          = /pool/condor/dir_18951
--------------------------------------------------------------------------------

   ################
   #  ModuleETau  #
   ################

Loading PileupWeightTool for '/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/data/pileup/Data_PileUp_UL2017_69p2.root' and '/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/data/pileup/MC_PileUp_UL2017_Summer19.root'
Loading BTagWeightTool for DeepCSV (medium WP)...
>>> BTagTool: [1m[33mWarning! [0m[33mHistogram 'etau/eff_DeepCSV_udsg_medium' does not exist in /afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/data/btag/DeepCSV_2017_12Apr2017_eff.root! Reverting to default efficiency histogram...[0m
>>> BTagTool: [1m[33mWarning! [0m[33mHistogram 'etau/eff_DeepCSV_c_medium' does not exist in /afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/data/btag/DeepCSV_2017_12Apr2017_eff.root! Reverting to default efficiency histogram...[0m
>>> BTagTool: [1m[33mWarning! [0m[33mHistogram 'etau/eff_DeepCSV_b_medium' does not exist in /afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/data/btag/DeepCSV_2017_12Apr2017_eff.root! Reverting to default efficiency histogram...[0m
>>> BTagTool: [1m[33mWarning! [0m[33mMade use of default efficiency histograms! The b tag weights from this module should be regarded as placeholders only,
and should NOT be used for analyses. B (mis)tag efficiencies in MC are analysis dependent. Please create your own
efficiency histogram with data/btag/getBTagEfficiencies.py after running all MC samples with BTagWeightTool.[0m
Loading TreeProducerETau for './pico_etau_105.root'
--------------------------------------------------------------------------------
>>> filename     = './pico_etau_105.root'
>>> year         = 2017
>>> dtype        = 'mc'
>>> channel      = 'etau'
>>> ismc         = True
>>> isdata       = False
>>> isembed      = False
>>> tes          = 1.0
>>> tessys       = None
>>> fes          = None
>>> ltf          = None
>>> jtf          = 1.0
>>> dotoppt      = True
>>> dozpt        = False
>>> dojec        = True
>>> dojecsys     = True
>>> dotight      = False
>>> useT1        = True
>>> jetCutPt     = 30
>>> bjetCutEta   = 2.7
>>> tauwp        = 0
>>> eleCutPt     = 36
>>> eleCutEta    = 2.1
>>> tauCutPt     = 20
>>> tauCutEta    = 2.3
>>> ZpeekReso    = 0.1
Pre-select 200375 entries out of 200375 (100.00%)
Processed    10000/  200375 entries,  4.99% (elapsed time     7.1s, curr speed    1.401 kHz, avg speed    1.401 kHz), accepted      377/   10001 events ( 3.77%)
Processed    20000/  200375 entries,  9.98% (elapsed time    11.4s, curr speed    2.369 kHz, avg speed    1.761 kHz), accepted      787/   20001 events ( 3.93%)
Processed    30000/  200375 entries, 14.97% (elapsed time    14.6s, curr speed    3.087 kHz, avg speed    2.055 kHz), accepted     1189/   30001 events ( 3.96%)
Processed    40000/  200375 entries, 19.96% (elapsed time    19.3s, curr speed    2.139 kHz, avg speed    2.075 kHz), accepted     1594/   40001 events ( 3.98%)
Processed    50000/  200375 entries, 24.95% (elapsed time    23.3s, curr speed    2.459 kHz, avg speed    2.142 kHz), accepted     1986/   50001 events ( 3.97%)
Processed    60000/  200375 entries, 29.94% (elapsed time    27.4s, curr speed    2.443 kHz, avg speed    2.187 kHz), accepted     2351/   60001 events ( 3.92%)
Processed    70000/  200375 entries, 34.93% (elapsed time    31.6s, curr speed    2.427 kHz, avg speed    2.218 kHz), accepted     2775/   70001 events ( 3.96%)
Processed    80000/  200375 entries, 39.93% (elapsed time    34.4s, curr speed    3.540 kHz, avg speed    2.327 kHz), accepted     3147/   80001 events ( 3.93%)
Processed    90000/  200375 entries, 44.92% (elapsed time    37.4s, curr speed    3.274 kHz, avg speed    2.404 kHz), accepted     3542/   90001 events ( 3.94%)
Processed   100000/  200375 entries, 49.91% (elapsed time    40.8s, curr speed    2.930 kHz, avg speed    2.448 kHz), accepted     3887/  100001 events ( 3.89%)
Processed   110000/  200375 entries, 54.90% (elapsed time    44.5s, curr speed    2.713 kHz, avg speed    2.470 kHz), accepted     4273/  110001 events ( 3.88%)
Processed   120000/  200375 entries, 59.89% (elapsed time    48.6s, curr speed    2.452 kHz, avg speed    2.469 kHz), accepted     4687/  120001 events ( 3.91%)
Processed   130000/  200375 entries, 64.88% (elapsed time    53.1s, curr speed    2.248 kHz, avg speed    2.450 kHz), accepted     5098/  130001 events ( 3.92%)
Processed   140000/  200375 entries, 69.87% (elapsed time    56.5s, curr speed    2.940 kHz, avg speed    2.480 kHz), accepted     5470/  140001 events ( 3.91%)
Processed   150000/  200375 entries, 74.86% (elapsed time    59.9s, curr speed    2.900 kHz, avg speed    2.504 kHz), accepted     5868/  150001 events ( 3.91%)
Processed   160000/  200375 entries, 79.85% (elapsed time    63.7s, curr speed    2.666 kHz, avg speed    2.513 kHz), accepted     6273/  160001 events ( 3.92%)
Processed   170000/  200375 entries, 84.84% (elapsed time    66.8s, curr speed    3.168 kHz, avg speed    2.544 kHz), accepted     6658/  170001 events ( 3.92%)
Processed   180000/  200375 entries, 89.83% (elapsed time    70.1s, curr speed    3.054 kHz, avg speed    2.568 kHz), accepted     7068/  180001 events ( 3.93%)
Processed   190000/  200375 entries, 94.82% (elapsed time    73.1s, curr speed    3.346 kHz, avg speed    2.600 kHz), accepted     7453/  190001 events ( 3.92%)
Processed   200000/  200375 entries, 99.81% (elapsed time    75.9s, curr speed    3.542 kHz, avg speed    2.635 kHz), accepted     7865/  200001 events ( 3.93%)
Processed 200375 preselected entries from /eos/cms/store/group/phys_tau/TauFW/nano/UL2017/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/RunIISummer19UL17NanoAODv2-106X_mc2017_realistic_v8-v1/NANOAODSIM/FFE9016D-DC64-4042-AA06-66288BF37B9B_skimjec_3.root (200375 entries). Finally selected 7886 entries
Total time 77.0 sec. to process 200375 events. Rate = 2603.8 Hz.
>>> cwd          = /pool/condor/dir_18951
>>> ls           = ['_condor_stdout', '.chirp.config', '.job.ad', 'lvigilan.cc', 'pico_etau_105.root', 'var', 'condor_exec.exe', 'x509_voms', 'tmp', '.machine.ad']
>>> getstorage('/eos/home-l/lvigilan/output_ETauFR_UL17_RUN1/UL2017/etau/TTToSemiLeptonic'), <EOS("/eos/home-l/lvigilan/output_ETauFR_UL17_RUN1/UL2017/etau/TTToSemiLeptonic") at 0x2ae3aad44d50>
>>> Executing: 'cp ./pico_etau_105.root /eos/home-l/lvigilan/output_ETauFR_UL17_RUN1/UL2017/etau/TTToSemiLeptonic'
>>> Removing './pico_etau_105.root'...
>>> picojob.py done after 95.6 seconds

Job complete at Mon Jun  7 19:06:05 CEST 2021
Took 1 minutes 37 seconds040 (2367592.105.000) 06/07 19:06:05 Started transferring output files
...
040 (2367592.105.000) 06/07 19:06:05 Finished transferring output files
...
005 (2367592.105.000) 06/07 19:06:05 Job terminated.
	(1) Normal termination (return value 0)
		Usr 0 00:01:06, Sys 0 00:00:03  -  Run Remote Usage
		Usr 0 00:00:00, Sys 0 00:00:00  -  Run Local Usage
		Usr 0 00:01:06, Sys 0 00:00:03  -  Total Remote Usage
		Usr 0 00:00:00, Sys 0 00:00:00  -  Total Local Usage
	16924  -  Run Bytes Sent By Job
	9930  -  Run Bytes Received By Job
	16924  -  Total Bytes Sent By Job
	9930  -  Total Bytes Received By Job
	Partitionable Resources :    Usage  Request Allocated 
	   Cpus                 :                 1         1 
	   Disk (KB)            :       78        1    261958 
	   Memory (MB)          :      157     2000      2000 

	Job terminated of its own accord at 2021-06-07T17:06:05Z.
...
