Could not find platform independent libraries <prefix>
Could not find platform dependent libraries <exec_prefix>
Consider setting $PYTHONHOME to <prefix>[:<exec_prefix>]
ImportError: No module named site
Job start at Wed Jan 20 16:30:35 CET 2021
Running job on machine Linux b7g42n0742.cern.ch 3.10.0-1062.18.1.el7.x86_64 #1 SMP Tue Mar 17 23:49:17 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux, host b7g42n0742.cern.ch
============================================================
$PWD=/pool/condor/dir_23803
$JOBID=1759045
$TASKID=4
$HOSTNAME=b7g42n0742.cern.ch
$TASKCMD=/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/python/processors/picojob.py -y 2017 -d 'mc' -c etau -M ModuleETau --copydir /eos/home-l/lvigilan/output_UL2017/2017/etau/ST_tW_antitop -t _etau_4 -i root://cms-xrd-global.cern.ch//store/mc/RunIISummer19UL17NanoAOD/ST_tW_antitop_5f_NoFullyHadronicDecays_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mc2017_realistic_v6-v1/270000/8B36E166-DA77-D14C-9E3D-4C155123CCC3.root root://cms-xrd-global.cern.ch//store/mc/RunIISummer19UL17NanoAOD/ST_tW_antitop_5f_NoFullyHadronicDecays_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mc2017_realistic_v6-v1/270000/B637F49D-8D31-7447-8B3B-8E6888D4436F.root root://cms-xrd-global.cern.ch//store/mc/RunIISummer19UL17NanoAOD/ST_tW_antitop_5f_NoFullyHadronicDecays_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mc2017_realistic_v6-v1/270000/EF697507-2B45-004B-9A53-2B0546E53DCD.root root://cms-xrd-global.cern.ch//store/mc/RunIISummer19UL17NanoAOD/ST_tW_antitop_5f_NoFullyHadronicDecays_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mc2017_realistic_v6-v1/270000/F7C099D2-3838-AD49-9C23-24E736E346F0.root root://cms-xrd-global.cern.ch//store/mc/RunIISummer19UL17NanoAOD/ST_tW_antitop_5f_NoFullyHadronicDecays_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mc2017_realistic_v6-v1/280000/35B9AF13-523A-8A4F-95A2-8F63C4A0D419.root
$WORKDIR=/pool/condor/dir_23803
>>> cd /afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src
>>> eval `scramv1 runtime -sh`
>>> cd /pool/condor/dir_23803
$PWD=/pool/condor/dir_23803
>>> /afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/python/processors/picojob.py -y 2017 -d 'mc' -c etau -M ModuleETau --copydir /eos/home-l/lvigilan/output_UL2017/2017/etau/ST_tW_antitop -t _etau_4 -i root://cms-xrd-global.cern.ch//store/mc/RunIISummer19UL17NanoAOD/ST_tW_antitop_5f_NoFullyHadronicDecays_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mc2017_realistic_v6-v1/270000/8B36E166-DA77-D14C-9E3D-4C155123CCC3.root root://cms-xrd-global.cern.ch//store/mc/RunIISummer19UL17NanoAOD/ST_tW_antitop_5f_NoFullyHadronicDecays_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mc2017_realistic_v6-v1/270000/B637F49D-8D31-7447-8B3B-8E6888D4436F.root root://cms-xrd-global.cern.ch//store/mc/RunIISummer19UL17NanoAOD/ST_tW_antitop_5f_NoFullyHadronicDecays_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mc2017_realistic_v6-v1/270000/EF697507-2B45-004B-9A53-2B0546E53DCD.root root://cms-xrd-global.cern.ch//store/mc/RunIISummer19UL17NanoAOD/ST_tW_antitop_5f_NoFullyHadronicDecays_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mc2017_realistic_v6-v1/270000/F7C099D2-3838-AD49-9C23-24E736E346F0.root root://cms-xrd-global.cern.ch//store/mc/RunIISummer19UL17NanoAOD/ST_tW_antitop_5f_NoFullyHadronicDecays_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mc2017_realistic_v6-v1/280000/35B9AF13-523A-8A4F-95A2-8F63C4A0D419.root
Error in <TGClient::TGClient>: can't open display "localhost:37.0", switching to batch mode...
 In case you run from a remote ssh session, reconnect with ssh -Y
--------------------------------------------------------------------------------
>>> era          = '2017'
>>> year         = 2017
>>> channel      = 'etau'
>>> modname      = 'ModuleETau'
>>> dtype        = 'mc'
>>> kwargs       = {'dtype': 'mc', 'verb': 0, 'era': '2017', 'year': 2017}
>>> maxevts      = None
>>> outdir       = '.'
>>> copydir      = '/eos/home-l/lvigilan/output_UL2017/2017/etau/ST_tW_antitop'
>>> infiles      = ['root://cms-xrd-global.cern.ch//store/mc/RunIISummer19UL17NanoAOD/ST_tW_antitop_5f_NoFullyHadronicDecays_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mc2017_realistic_v6-v1/270000/8B36E166-DA77-D14C-9E3D-4C155123CCC3.root', 'root://cms-xrd-global.cern.ch//store/mc/RunIISummer19UL17NanoAOD/ST_tW_antitop_5f_NoFullyHadronicDecays_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mc2017_realistic_v6-v1/270000/B637F49D-8D31-7447-8B3B-8E6888D4436F.root', 'root://cms-xrd-global.cern.ch//store/mc/RunIISummer19UL17NanoAOD/ST_tW_antitop_5f_NoFullyHadronicDecays_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mc2017_realistic_v6-v1/270000/EF697507-2B45-004B-9A53-2B0546E53DCD.root', 'root://cms-xrd-global.cern.ch//store/mc/RunIISummer19UL17NanoAOD/ST_tW_antitop_5f_NoFullyHadronicDecays_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mc2017_realistic_v6-v1/270000/F7C099D2-3838-AD49-9C23-24E736E346F0.root', 'root://cms-xrd-global.cern.ch//store/mc/RunIISummer19UL17NanoAOD/ST_tW_antitop_5f_NoFullyHadronicDecays_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mc2017_realistic_v6-v1/280000/35B9AF13-523A-8A4F-95A2-8F63C4A0D419.root']
>>> outfname     = './pico_etau_etau_4.root'
>>> branchsel    = '/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/python/TauFW/PicoProducer/processors/keep_and_drop_skim.txt'
>>> json         = None
>>> prefetch     = False
>>> cwd          = /pool/condor/dir_23803
--------------------------------------------------------------------------------

   ################
   #  ModuleETau  #
   ################

Loading PileupWeightTool for '/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/data/pileup/Data_PileUp_2017_69p2.root' and '/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/data/pileup/MC_PileUp_2017_Winter17_V2_new_pmx.root'
Loading BTagWeightTool for DeepCSV (medium WP)...
>>> BTagTool: [1m[33mWarning! [0m[33mHistogram 'etau/eff_DeepCSV_udsg_medium' does not exist in /afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/data/btag/DeepCSV_2017_12Apr2017_eff.root! Reverting to default efficiency histogram...[0m
>>> BTagTool: [1m[33mWarning! [0m[33mHistogram 'etau/eff_DeepCSV_c_medium' does not exist in /afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/data/btag/DeepCSV_2017_12Apr2017_eff.root! Reverting to default efficiency histogram...[0m
>>> BTagTool: [1m[33mWarning! [0m[33mHistogram 'etau/eff_DeepCSV_b_medium' does not exist in /afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/data/btag/DeepCSV_2017_12Apr2017_eff.root! Reverting to default efficiency histogram...[0m
>>> BTagTool: [1m[33mWarning! [0m[33mMade use of default efficiency histograms! The b tag weights from this module should be regarded as placeholders only,
and should NOT be used for analyses. B (mis)tag efficiencies in MC are analysis dependent. Please create your own
efficiency histogram with data/btag/getBTagEfficiencies.py after running all MC samples with BTagWeightTool.[0m
Loading TreeProducerETau for './pico_etau_etau_4.root'
--------------------------------------------------------------------------------
>>> filename     = './pico_etau_etau_4.root'
>>> year         = 2017
>>> dtype        = 'mc'
>>> channel      = 'etau'
>>> ismc         = True
>>> isdata       = False
>>> isembed      = False
>>> tes          = None
>>> tessys       = None
>>> ltf          = 1.0
>>> jtf          = 1.0
>>> dotoppt      = False
>>> dozpt        = False
>>> dojec        = True
>>> dojecsys     = True
>>> dotight      = False
>>> jetCutPt     = 30
>>> bjetCutEta   = 2.7
>>> tauwp        = 0
>>> eleCutPt     = 36
>>> eleCutEta    = 2.1
>>> tauCutPt     = 20
>>> tauCutEta    = 2.3
Pre-select 473425 entries out of 473425 (100.00%)
Traceback (most recent call last):
  File "/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/python/processors/picojob.py", line 111, in <module>
    p.run()
  File "/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/python/PhysicsTools/NanoAODTools/postprocessing/framework/postprocessor.py", line 234, in run
    eventRange=eventRange, maxEvents=self.maxEntries
  File "/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/python/PhysicsTools/NanoAODTools/postprocessing/framework/eventloop.py", line 82, in eventLoop
    ret = m.analyze(e)
  File "/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/python/TauFW/PicoProducer/analysis/ModuleETau.py", line 177, in analyze
    self.fillEventBranches(event)
  File "/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/python/TauFW/PicoProducer/analysis/ModuleTauPair.py", line 148, in fillEventBranches
    self.out.metfilter[0]       = self.filter(event)
  File "<string>", line 1, in <lambda>
  File "/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/python/PhysicsTools/NanoAODTools/postprocessing/framework/datamodel.py", line 18, in __getattr__
    return self._tree.readBranch(name)
  File "/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/python/PhysicsTools/NanoAODTools/postprocessing/framework/treeReaderArrayTools.py", line 76, in readBranch
    raise RuntimeError("Unknown branch %s" % branchName)
RuntimeError: Unknown branch Flag_ecalBadCalibFilterV2

Job complete at Wed Jan 20 16:31:29 CET 2021
Took 0 minutes 54 seconds040 (1759045.004.000) 01/20 16:31:44 Started transferring output files
	Seconds spent in queue: 2417
...
040 (1759045.004.000) 01/20 16:31:45 Finished transferring output files
...
005 (1759045.004.000) 01/20 16:32:00 Job terminated.
	(1) Normal termination (return value 0)
		Usr 0 00:00:16, Sys 0 00:00:01  -  Run Remote Usage
		Usr 0 00:00:00, Sys 0 00:00:00  -  Run Local Usage
		Usr 0 00:00:16, Sys 0 00:00:01  -  Total Remote Usage
		Usr 0 00:00:00, Sys 0 00:00:00  -  Total Local Usage
	9872  -  Run Bytes Sent By Job
	9902  -  Run Bytes Received By Job
	9872  -  Total Bytes Sent By Job
	9902  -  Total Bytes Received By Job
	Partitionable Resources :    Usage  Request Allocated 
	   Cpus                 :        0        1         1 
	   Disk (KB)            :       80        1    313056 
	   Memory (MB)          :        9     2000      2000 

	Job terminated of its own accord at 2021-01-20T15:31:29Z.
...
